# SpicyDiff Architecture & Technical Manual

> A detailed guide to how SpicyDiff works internally â€” for contributors, curious developers, and anyone who wants to understand the principles behind the project.

---

## Table of Contents

1. [What is SpicyDiff?](#1-what-is-spicydiff)
2. [How GitHub Actions Work (Background)](#2-how-github-actions-work)
3. [System Architecture Overview](#3-system-architecture-overview)
4. [Complete Execution Flow](#4-complete-execution-flow)
5. [Module Deep Dive](#5-module-deep-dive)
   - 5.1 [Entry Point & Orchestration (`main.py`)](#51-entry-point--orchestration)
   - 5.2 [Configuration Layer (`config.py` + `repo_config.py`)](#52-configuration-layer)
   - 5.3 [LLM Provider System (`providers.py`)](#53-llm-provider-system)
   - 5.4 [Diff Parsing (`diff_parser.py`)](#54-diff-parsing)
   - 5.5 [Smart Context Extraction (`context.py`)](#55-smart-context-extraction)
   - 5.6 [Prompt Engineering (`prompts.py`)](#56-prompt-engineering)
   - 5.7 [LLM Client (`llm_client.py`)](#57-llm-client)
   - 5.8 [GitHub Comment Posting (`github_client.py`)](#58-github-comment-posting)
   - 5.9 [Data Models (`models.py`)](#59-data-models)
   - 5.10 [Logging (`logger.py`)](#510-logging)
6. [Review Strategies](#6-review-strategies)
7. [Prompt Engineering Principles](#7-prompt-engineering-principles)
8. [Docker & Deployment](#8-docker--deployment)
9. [Module Dependency Graph](#9-module-dependency-graph)
10. [Configuration Priority & Merging](#10-configuration-priority--merging)
11. [Error Handling & Resilience](#11-error-handling--resilience)
12. [Testing Strategy](#12-testing-strategy)

---

## 1. What is SpicyDiff?

SpicyDiff is a **GitHub Action** that uses Large Language Models (LLMs) to automatically review code changes in Pull Requests. It reads the `git diff`, sends it to an AI model with a personality prompt, and posts the review as a comment on the PR.

What makes it unique:

- **Personality-driven reviews**: Three modes (ROAST / PRAISE / SECURITY) give the AI different personas
- **Multi-provider support**: Works with 10+ LLM providers (DeepSeek, Qwen, OpenAI, Gemini, etc.)
- **Smart multi-file review**: Large PRs are reviewed file-by-file with surrounding code context
- **Team-customizable rules**: Teams define their own coding standards via `.spicydiff.yml`

---

## 2. How GitHub Actions Work

Understanding SpicyDiff requires understanding how GitHub Actions work:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Developer's Repository                   â”‚
â”‚                                                              â”‚
â”‚  .github/workflows/spicydiff.yml     â† Workflow definition   â”‚
â”‚  src/                                â† Their code            â”‚
â”‚  .spicydiff.yml                      â† Optional team config  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚  PR opened / updated
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     GitHub Actions Runner                    â”‚
â”‚                                                              â”‚
â”‚  1. Reads spicydiff.yml workflow                             â”‚
â”‚  2. Sees: uses: johnzhang777/spicydiff@v1                    â”‚
â”‚  3. Downloads SpicyDiff repo at tag v1                       â”‚
â”‚  4. Builds Docker image from Dockerfile                      â”‚
â”‚  5. Runs the container with INPUT_* environment variables    â”‚
â”‚  6. Container exits â†’ runner cleans up                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Key points:
- SpicyDiff runs as a **Docker container** on GitHub's infrastructure
- The developer never installs or deploys anything
- GitHub passes all `with:` inputs as `INPUT_*` environment variables
- GitHub also injects context variables like `GITHUB_REPOSITORY`, `GITHUB_EVENT_PATH`, etc.

---

## 3. System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SpicyDiff Container                          â”‚
â”‚                                                                     â”‚
â”‚  entrypoint.sh                                                      â”‚
â”‚  â””â”€â”€ python -m spicydiff.main                                       â”‚
â”‚       â”‚                                                             â”‚
â”‚       â”œâ”€â”€ config.py â†â”€â”€ repo_config.py â†â”€â”€ .spicydiff.yml           â”‚
â”‚       â”‚       â””â”€â”€ providers.py                                      â”‚
â”‚       â”‚                                                             â”‚
â”‚       â”œâ”€â”€ diff_parser.py â”€â”€â”€â”€ GitHub API â”€â”€â”€â”€ PR files + patches    â”‚
â”‚       â”‚                                                             â”‚
â”‚       â”œâ”€â”€ context.py â”€â”€â”€â”€ GitHub API â”€â”€â”€â”€ full file contents        â”‚
â”‚       â”‚                                                             â”‚
â”‚       â”œâ”€â”€ prompts.py â”€â”€â”€â”€ builds system + user prompts              â”‚
â”‚       â”‚                                                             â”‚
â”‚       â”œâ”€â”€ llm_client.py â”€â”€â”€â”€ LLM API â”€â”€â”€â”€ AI response (JSON)        â”‚
â”‚       â”‚                                                             â”‚
â”‚       â””â”€â”€ github_client.py â”€â”€â”€â”€ GitHub API â”€â”€â”€â”€ PR comment          â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**External dependencies:**
- **GitHub API** (via PyGithub): Read PR diff, fetch file contents, post comments
- **LLM API** (via OpenAI SDK): Send prompts, receive structured JSON reviews
- **Docker**: Container runtime provided by GitHub Actions

---

## 4. Complete Execution Flow

Here is exactly what happens, step by step, from the moment a PR is opened:

### Phase 0: Trigger & Container Start

```
Developer opens PR â†’ GitHub reads .github/workflows/spicydiff.yml
â†’ GitHub builds Docker image from Dockerfile
â†’ Docker starts container with --workdir /github/workspace
â†’ entrypoint.sh sets PYTHONPATH=/app
â†’ python -m spicydiff.main â†’ calls main()
```

### Phase 1: Resolve PR Number

```python
# main.py: _resolve_pr_number()
```

GitHub provides the event payload at `GITHUB_EVENT_PATH` (a JSON file). SpicyDiff reads this file to extract the PR number:

```json
{
  "pull_request": {
    "number": 42,
    ...
  }
}
```

The PR number is stored in the `PR_NUMBER` environment variable for later use by `config.py`.

### Phase 2: Load Configuration

```python
# config.py: Config.from_env()
```

Configuration comes from **three sources**, merged in priority order:

```
Priority 1 (highest): GitHub Action inputs (INPUT_* env vars)
Priority 2:           .spicydiff.yml in the user's repo
Priority 3 (lowest):  Built-in defaults
```

The process:
1. Read required inputs: `INPUT_GITHUB_TOKEN`, `INPUT_API_KEY`
2. Resolve the LLM provider (see Section 5.3)
3. Load `.spicydiff.yml` from the workspace (if it exists)
4. Merge all settings into a frozen `Config` dataclass

### Phase 3: Fetch & Parse PR Diff

```python
# diff_parser.py: get_pr() + fetch_pr_diff()
```

1. Connect to GitHub API using `PyGithub`
2. Fetch the PR object by repository name + PR number
3. Iterate through all changed files in the PR
4. For each file:
   - Check against ignore patterns (lock files, images, binaries)
   - Check against user-provided exclude patterns
   - Check if adding this file exceeds `max_diff_chars` budget
   - Parse the unified diff with `unidiff` to extract added line numbers
5. Return a `PRDiff` containing all `FileDiff` objects

```
PR has 20 files
  â”œâ”€â”€ package-lock.json    â†’ SKIP (built-in ignore)
  â”œâ”€â”€ logo.png             â†’ SKIP (binary)
  â”œâ”€â”€ *.test.js            â†’ SKIP (user exclude pattern)
  â”œâ”€â”€ src/main.py          â†’ INCLUDE (2,400 chars)
  â”œâ”€â”€ src/utils.py          â†’ INCLUDE (1,800 chars)
  â”œâ”€â”€ ...
  â””â”€â”€ src/huge-file.py     â†’ SKIP (would exceed 60,000 char budget)
                               PRDiff.truncated = True
```

### Phase 4: Choose Review Strategy

```python
# main.py: run()
if len(pr_diff.files) <= MULTI_FILE_THRESHOLD:  # default: 3
    result = _single_pass_review(...)
else:
    result = _multi_file_review(...)
```

Two strategies:

| Strategy | When | How | LLM calls |
|----------|------|-----|-----------|
| **Single-pass** | â‰¤3 files | Send entire diff in one prompt | 1 |
| **Multi-file** | 4+ files | Review each file individually, then merge | N + 1 |

See [Section 6](#6-review-strategies) for details.

### Phase 5: Build Prompts

```python
# prompts.py: build_system_prompt() + build_user_prompt()
```

The system prompt is assembled from four pieces:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ System Prompt                              â”‚
â”‚                                            â”‚
â”‚ 1. System Context (JSON format rules)      â”‚
â”‚ 2. Persona (ROAST / PRAISE / SECURITY)     â”‚
â”‚ 3. Custom Rules (from .spicydiff.yml)      â”‚
â”‚ 4. Output Schema (JSON structure)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The user prompt contains the diff:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Prompt                                 â”‚
â”‚                                             â”‚
â”‚ "Please review the following code changes:" â”‚
â”‚                                             â”‚
â”‚ ```diff                                     â”‚
â”‚ --- a/src/main.py                           â”‚
â”‚ +++ b/src/main.py                           â”‚
â”‚ @@ -10,3 +10,5 @@                           â”‚
â”‚ +    x = 86400                              â”‚
â”‚ +    if True:                               â”‚
â”‚ ```                                         â”‚
â”‚                                             â”‚
â”‚ (optional: smart context block)             â”‚
â”‚ (optional: truncation notice)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 6: Call LLM

```python
# llm_client.py: call_llm()
```

1. Create an OpenAI client pointed at the provider's base URL
2. Send the system + user prompts via `chat.completions.create()`
3. The LLM returns raw text (supposed to be JSON)
4. Strip any markdown code fences (```` ```json ... ``` ````)
5. Parse as JSON
6. Validate against the Pydantic `ReviewResult` schema
7. Return the structured result

```
LLM Response (raw text):
```json
{
  "summary": "è¿™ä»£ç åƒæ²¡ç…®ç†Ÿçš„ç‰›æ’!",
  "score": 25,
  "reviews": [
    {"file_path": "src/main.py", "line_number": 10, "comment": "Magic number!"}
  ]
}
```
â†’ Strip fences â†’ Parse JSON â†’ Validate schema â†’ ReviewResult object
```

### Phase 7: Post Results

```python
# github_client.py: post_summary_comment()
```

Everything is posted as **one single comment** on the PR:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ## SpicyDiff Review ğŸ”¥                    â”‚
â”‚ Mode: ğŸŒ¶ï¸ åœ°ç‹±å¨æˆ¿æ¨¡å¼ (ROAST)               â”‚
â”‚ Score: 35/100 ğŸ”¥                          â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
â”‚ Overall summary text...                   â”‚
â”‚                                           â”‚
â”‚ ### ğŸ“‚ æ–‡ä»¶å®¡æŸ¥è¯¦æƒ…                         â”‚
â”‚                                           â”‚
â”‚ â–¶ src/main.py    â€”  25/100  ğŸ—‘ï¸            â”‚
â”‚   (click to expand full review)           â”‚
â”‚                                           â”‚
â”‚ â–¶ src/utils.py   â€”  50/100  ğŸ˜            â”‚
â”‚   (click to expand full review)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The comment uses a hidden HTML marker (`<!-- spicydiff-review -->`) so that on subsequent PR updates, SpicyDiff finds and **updates** the existing comment instead of creating a new one.

---

## 5. Module Deep Dive

### 5.1 Entry Point & Orchestration

**Files:** `__main__.py`, `main.py`, `entrypoint.sh`

`entrypoint.sh` is the Docker container's entry point. It sets `PYTHONPATH=/app` (critical because GitHub Actions overrides the working directory to `/github/workspace`) and then runs `python -m spicydiff.main`.

`main.py` contains the `run()` function, which is the pipeline orchestrator. It follows a strict 5-step sequence:

1. Resolve PR number from event context
2. Load configuration (env vars + repo config)
3. Fetch and parse the PR diff
4. Choose and execute the review strategy (single-pass or multi-file)
5. Post the result as a GitHub comment (or log it in dry-run mode)

All imports are done lazily inside `run()` so that if a dependency is missing, the error message is clear.

### 5.2 Configuration Layer

**Files:** `config.py`, `repo_config.py`

The configuration system has two layers:

**Layer 1: `config.py`** â€” Reads `INPUT_*` environment variables that GitHub Actions injects from the `with:` block in the workflow YAML.

**Layer 2: `repo_config.py`** â€” Optionally loads a `.spicydiff.yml` file from the user's repository root. This allows teams to commit shared settings (mode, language, custom rules, exclude patterns) alongside their code.

**Merging logic:**

```python
# Pseudo-code for the merge
final_mode = action_input_mode or repo_config_mode or "ROAST"
final_language = action_input_language or repo_config_language or "en"
final_exclude = action_input_exclude + repo_config_exclude  # combined
final_rules = action_input_rules + repo_config_rules         # combined
```

Action inputs always win. Repo config provides team defaults. Built-in defaults are the fallback.

### 5.3 LLM Provider System

**File:** `providers.py`

SpicyDiff supports any LLM with an OpenAI-compatible API. The provider system has three tiers:

```
Tier 1: Provider shortcut     â†’ provider: "deepseek"
Tier 2: Manual base URL       â†’ base-url: "https://custom.com/v1"
Tier 3: Default (OpenAI)      â†’ (no provider or base-url set)
```

The `PROVIDERS` dictionary maps shortcut names to `ProviderPreset` objects:

```python
"deepseek" â†’ ProviderPreset(
    base_url="https://api.deepseek.com/v1",
    default_model="deepseek-chat",
)
```

The `resolve_provider()` function implements the priority chain:

```
explicit base_url wins â†’ provider shortcut â†’ default (OpenAI)
```

**Why this works for all providers:** Most modern LLM providers (DeepSeek, Qwen, Zhipu, Moonshot, etc.) expose OpenAI-compatible APIs â€” they accept the same request format and return the same response format. So one `openai.OpenAI(base_url=...)` client works for all of them.

### 5.4 Diff Parsing

**File:** `diff_parser.py`

This module fetches the PR diff from GitHub and transforms it into structured data.

**Step 1: File filtering**

Files are filtered through two layers:
- **Built-in regex patterns**: Lock files (`package-lock.json`, `yarn.lock`, `Cargo.lock`, etc.), binary files (`.png`, `.pdf`, `.woff2`, etc.), OS files (`.DS_Store`)
- **User glob patterns**: From `exclude-patterns` input or `.spicydiff.yml` `exclude` list

**Step 2: Size budgeting**

The total diff size is capped at `max_diff_chars` (default 60,000 characters â‰ˆ 15,000 tokens). Files are added in order; once the budget is exhausted, remaining files are skipped and `PRDiff.truncated` is set to `True`.

**Step 3: Line number extraction**

For each included file, the `unidiff` library parses the patch text to extract which line numbers in the new file were added or modified. This information is stored as `added_lines: Dict[int, str]` â€” a mapping of line numbers to their content.

This is used later for:
- Smart context extraction (which function contains the changed lines?)
- Line-level comment validation (is the LLM's line number actually in the diff?)

### 5.5 Smart Context Extraction

**File:** `context.py`

When reviewing a single file (in multi-file mode), just seeing the diff isn't enough â€” the LLM needs to understand the **surrounding code** to give useful feedback.

**How it works:**

1. Fetch the full file content from GitHub at the PR's head commit
2. For each changed line, find the **enclosing function or class** using:
   - Indentation analysis (walk backwards to find a line with less indentation)
   - Block pattern matching (regex patterns for `def`, `function`, `class`, `func`, `pub fn`, etc.)
3. Merge overlapping ranges (if two changes are in the same function, extract it once)
4. Truncate to `MAX_CONTEXT_CHARS` (3,000) to avoid bloating the prompt

**Example:**

```python
# The LLM sees this context:
  10 | def calculate_total(items):
  11 |     total = 0
  12 |     for item in items:
  13 |         total += item.price * item.quantity  # â† changed line
  14 |     return total

# Instead of just:
@@ -13 +13 @@
+         total += item.price * item.quantity
```

The context makes a huge difference â€” the LLM can now understand that `total` is an accumulator, `items` is iterable, and the function returns a sum.

**Supported languages:** Python, JavaScript/TypeScript, Go, Java/C#/Kotlin, Rust (via block pattern regex).

### 5.6 Prompt Engineering

**File:** `prompts.py`

The prompt system is built from modular, internationalized components.

**System prompt structure:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. System Context                        â”‚
â”‚    "You are a code review assistant.     â”‚
â”‚     Output strict JSON only..."          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. Persona (mode-dependent)              â”‚
â”‚    ROAST: "Gordon Ramsay-style..."       â”‚
â”‚    PRAISE: "Enthusiastic junior dev..."  â”‚
â”‚    SECURITY: "Paranoid auditor..."       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. Custom Rules (optional)               â”‚
â”‚    "Also check these team rules:         â”‚
â”‚     1. All functions need docstrings     â”‚
â”‚     2. No hardcoded URLs"               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. Output Schema                         â”‚
â”‚    "Return JSON: {summary, score,        â”‚
â”‚     reviews: [{file_path, line_number,   â”‚
â”‚     comment}]}"                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Every section has zh and en variants. The language parameter determines which variant is used for **all** sections â€” not just the persona.

**Four prompt builders:**

| Function | Used in | Purpose |
|----------|---------|---------|
| `build_system_prompt()` | All modes | Builds the complete system instruction |
| `build_user_prompt()` | Single-pass | Sends the entire diff at once |
| `build_file_review_prompt()` | Multi-file | Sends one file's diff + context |
| `build_merge_summary_prompt()` | Multi-file | Asks LLM to merge per-file reviews |

### 5.7 LLM Client

**File:** `llm_client.py`

A thin wrapper around the OpenAI SDK with added resilience.

**Features:**
- **Automatic retry**: The `openai` SDK's built-in retry (default 3 retries with exponential backoff) handles 429 (rate limit) and 5xx (server error)
- **Configurable timeout**: Default 120 seconds per request
- **Code fence stripping**: Some models return `` ```json ... ``` `` despite being told not to â€” we strip these before parsing
- **Schema validation**: The JSON response is validated against the `ReviewResult` Pydantic model

**Error handling chain:**

```
API call fails â†’ retry 3 times â†’ still fails â†’ sys.exit(1)
Response empty â†’ sys.exit(1)
JSON parse fails â†’ log raw output â†’ sys.exit(1)
Schema invalid (e.g. score=999) â†’ log validation error â†’ sys.exit(1)
All good â†’ return ReviewResult
```

### 5.8 GitHub Comment Posting

**File:** `github_client.py`

Posts one unified comment containing the entire review.

**Comment structure (multi-file mode):**

```markdown
<!-- spicydiff-review -->          â† hidden marker for identification
## SpicyDiff Review ğŸ”¥
**Mode**: ğŸŒ¶ï¸ Hell's Kitchen (ROAST)
**Score**: 35/100 ğŸ”¥
---
Overall summary from merge call...

### ğŸ“‚ Per-file Review Details

<details>
<summary><b><code>src/main.py</code></b> â€” 25/100 ğŸ—‘ï¸</summary>

Full review text for this file...

**Line Comments:**
- **L10**: Magic number 86400 â€” use a named constant!
- **L23**: Nesting 5 levels deep â€” refactor this!

</details>

<details>
<summary><b><code>src/utils.py</code></b> â€” 50/100 ğŸ˜</summary>

Full review text for this file...

**Line Comments:**
- **L45**: Bare except â€” catch specific exceptions!

</details>
```

**Comment update logic:**
1. Search existing PR comments for the `<!-- spicydiff-review -->` marker
2. If found â†’ **edit** the existing comment (avoids spam on re-runs)
3. If not found â†’ **create** a new comment

**Score emoji mapping:**

| Score | Emoji |
|-------|-------|
| 0â€“19 | ğŸ—‘ï¸ |
| 20â€“39 | ğŸ”¥ |
| 40â€“59 | ğŸ˜ |
| 60â€“79 | ğŸ‘ |
| 80â€“100 | ğŸš€ |

### 5.9 Data Models

**File:** `models.py`

Pydantic models ensure type safety and validation:

```
Mode (Enum)
â”œâ”€â”€ ROAST
â”œâ”€â”€ PRAISE
â””â”€â”€ SECURITY

Language (Enum)
â”œâ”€â”€ ZH
â””â”€â”€ EN

InlineReview
â”œâ”€â”€ file_path: str
â”œâ”€â”€ line_number: int (â‰¥1)
â””â”€â”€ comment: str (non-empty)

ReviewResult (LLM returns this)
â”œâ”€â”€ summary: str (non-empty)
â”œâ”€â”€ score: int (0-100)
â””â”€â”€ reviews: List[InlineReview]

FileReviewSummary (per-file metadata)
â”œâ”€â”€ file_path: str
â”œâ”€â”€ score: int
â”œâ”€â”€ summary: str
â””â”€â”€ comment_count: int

FullReviewResult (multi-file aggregate)
â”œâ”€â”€ summary: str
â”œâ”€â”€ score: int
â”œâ”€â”€ reviews: List[InlineReview]
â””â”€â”€ file_summaries: List[FileReviewSummary]
```

### 5.10 Logging

**File:** `logger.py`

A custom logger that maps Python log levels to GitHub Actions annotations:

| Python level | GitHub Actions output |
|---|---|
| `log.info("msg")` | `msg` |
| `log.warning("msg")` | `::warning::msg` |
| `log.error("msg")` | `::error::msg` |

GitHub Actions renders `::warning::` and `::error::` as yellow/red annotations in the workflow run log, making issues easy to spot.

---

## 6. Review Strategies

### Single-pass (â‰¤3 files)

```
All file diffs â†’ concatenate â†’ one prompt â†’ one LLM call â†’ ReviewResult
```

**Pros:** Fast, cheap (1 API call), simple.
**Cons:** LLM may lose focus with multiple files in one prompt.

### Multi-file (4+ files)

```
File 1 diff + context â†’ LLM call â†’ FileResult 1
File 2 diff + context â†’ LLM call â†’ FileResult 2
...
File N diff + context â†’ LLM call â†’ FileResult N
                                        â”‚
All FileResults â†’ merge prompt â†’ LLM call â†’ FullReviewResult
```

**Pros:** Each file gets focused attention. Smart context helps the LLM understand the code. Per-file summaries are preserved in the final comment.
**Cons:** More API calls (N+1), more expensive, slower.

**The threshold** (`MULTI_FILE_THRESHOLD = 3`) is a balance between quality and cost. Users can't change it currently, but it can be adjusted in the source code.

---

## 7. Prompt Engineering Principles

### 7.1 Strict JSON Output

The system prompt explicitly tells the LLM:
- Output pure JSON only
- No markdown code fences
- No extra fields

Despite this, some models still add `` ```json `` wrappers â€” hence the `_strip_code_fences()` fallback in `llm_client.py`.

### 7.2 Persona Consistency

Each mode has a carefully crafted persona that maintains the character throughout:
- **ROAST**: Insults use cooking/kitchen metaphors consistently (not random insults)
- **PRAISE**: Over-the-top enthusiasm with specific emoji patterns
- **SECURITY**: Professional audit report tone with severity tags

### 7.3 Line Number Accuracy

The prompt explicitly instructs the LLM to use **new file line numbers** (the `+++` side of the diff), not diff offsets. This is clarified in both languages to reduce errors.

### 7.4 Custom Rules Injection

Team rules are injected between the persona and the output schema:

```
[persona instructions]

In addition to the above, also check these team rules:
1. All functions must have docstrings
2. No hardcoded URLs

[JSON output schema]
```

This placement ensures the LLM treats custom rules with the same importance as the built-in review criteria.

---

## 8. Docker & Deployment

### Container Structure

```
/app/                           â† PYTHONPATH points here
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ entrypoint.sh               â† ENTRYPOINT (sets PYTHONPATH, runs Python)
â””â”€â”€ spicydiff/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ __main__.py
    â”œâ”€â”€ main.py
    â””â”€â”€ ... (all modules)

/github/workspace/              â† GitHub's --workdir (user's repo)
â”œâ”€â”€ .github/workflows/
â”œâ”€â”€ .spicydiff.yml              â† repo config loaded from here
â”œâ”€â”€ src/
â””â”€â”€ ...
```

### Why `entrypoint.sh` is needed

GitHub Actions overrides the Docker `WORKDIR` to `/github/workspace` (the user's repository). Without `entrypoint.sh` setting `PYTHONPATH=/app`, Python would look for `spicydiff` in `/github/workspace/` and fail with `ModuleNotFoundError`.

### Security

The container runs as non-root user `spicydiff` (UID 1001) for security best practices.

---

## 9. Module Dependency Graph

```
main.py
â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ models.py (Mode, Language)
â”‚   â”œâ”€â”€ providers.py (resolve_provider)
â”‚   â””â”€â”€ repo_config.py (.spicydiff.yml)
â”‚       â””â”€â”€ logger.py
â”œâ”€â”€ diff_parser.py (PyGithub + unidiff)
â”‚   â””â”€â”€ logger.py
â”œâ”€â”€ context.py (PyGithub)
â”‚   â””â”€â”€ logger.py
â”œâ”€â”€ prompts.py
â”‚   â””â”€â”€ models.py (Mode, Language)
â”œâ”€â”€ llm_client.py (openai SDK)
â”‚   â”œâ”€â”€ models.py (ReviewResult)
â”‚   â””â”€â”€ logger.py
â”œâ”€â”€ github_client.py (PyGithub)
â”‚   â”œâ”€â”€ models.py (Mode, Language, ReviewResult, FullReviewResult)
â”‚   â””â”€â”€ logger.py
â””â”€â”€ logger.py
```

**External library usage:**
- `PyGithub` â†’ GitHub API (diff_parser, context, github_client)
- `openai` â†’ LLM API (llm_client)
- `unidiff` â†’ Git diff parsing (diff_parser)
- `pydantic` â†’ Data validation (models)
- `PyYAML` â†’ Config file parsing (repo_config)

---

## 10. Configuration Priority & Merging

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Priority 1: Action Inputs            â”‚
â”‚  (from workflow YAML `with:` block)          â”‚
â”‚  e.g. mode: "SECURITY"                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Priority 2: .spicydiff.yml           â”‚
â”‚  (from user's repo root)                     â”‚
â”‚  e.g. mode: ROAST, rules: [...]              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Priority 3: Built-in Defaults        â”‚
â”‚  mode=ROAST, language=en, temp=0.7           â”‚
â”‚  max_tokens=4096, max_diff_chars=60000       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**List fields** (exclude patterns, custom rules) are **merged** from both sources rather than overridden â€” so a team can set base rules in `.spicydiff.yml` and a workflow can add more.

---

## 11. Error Handling & Resilience

| Error | Handling |
|-------|----------|
| Missing required env var | `sys.exit(1)` with `::error::` annotation |
| Invalid provider name | `sys.exit(1)` listing available providers |
| LLM API timeout | OpenAI SDK retries 3 times with backoff |
| LLM API rate limit (429) | OpenAI SDK retries automatically |
| LLM returns non-JSON | Log raw output, `sys.exit(1)` |
| LLM returns invalid schema | Log validation error, `sys.exit(1)` |
| GitHub API rate limit (429) | Custom retry with exponential backoff |
| GitHub API permission denied (403) | Log warning, do not retry |
| Diff parsing fails (unidiff) | Log warning, include raw patch anyway |
| `.spicydiff.yml` invalid | Log warning, use defaults |
| No reviewable files in PR | Log info, exit cleanly (success) |

---

## 12. Testing Strategy

**142 unit tests** covering all modules:

| Test file | What it tests |
|-----------|--------------|
| `test_models.py` | Pydantic validation (valid/invalid scores, empty summaries, etc.) |
| `test_providers.py` | Provider resolution, shortcuts, case-insensitivity, unknown providers |
| `test_prompts.py` | All prompt builders Ã— all modes Ã— all languages, custom rules injection |
| `test_diff_parser.py` | File ignore patterns, glob matching, size truncation, data classes |
| `test_context.py` | Block detection, range merging, truncation, multi-language patterns |
| `test_llm_client.py` | Mock OpenAI calls, JSON parsing, fence stripping, error exits |
| `test_github_client.py` | Score emoji mapping, summary building, mode labels, HTML marker |
| `test_repo_config.py` | YAML loading, missing files, invalid YAML, key variants |
| `test_logger.py` | Log level mapping, GitHub Actions annotations, idempotency |

**LLM calls are mocked** â€” tests never hit a real API. The `unittest.mock.patch` decorator replaces `OpenAI` with a mock that returns predefined responses.

**CI workflow** (`.github/workflows/ci.yml`) runs tests on Python 3.9, 3.10, 3.11, and 3.12 on every push and PR.
